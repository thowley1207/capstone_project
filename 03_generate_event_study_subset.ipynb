{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ39tKCkKUYL/2+UM7O/Wb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thowley1207/capstone_project/blob/main/03_generate_event_study_subset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9v8LUrfdRV1"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade wrds\n",
        "!wget https://raw.githubusercontent.com/thowley1207/capstone_project/main/colab_initialization/initializer.py\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "import initializer\n",
        "initializer.initialize_colab()\n",
        "db = initializer.initialize_wrds_connection()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "SET DATA SUBDIRECTORIES AND FORM TYPE PREFIX\n",
        "WHEN APPLICABLE, THIS FORM TYPE PREFIX WILL BE USED MOVING FORWARD\n",
        "'''\n",
        "data_subdir = 'data/edgar_wrds_linking/'\n",
        "file_prefix = '8k_'\n",
        "\n",
        "'''\n",
        "ADDITIONAL FILE NAMES CARRIED DOWN FROM PRIOR WORK\n",
        "'''\n",
        "filtered_index_data_w_permno_file_name = (\n",
        "    'filtered_index_data_w_permno.pkl')\n",
        "\n",
        "'''\n",
        "NEW FILE NAMES FOR USE BELOW\n",
        "'''\n",
        "event_subset_file_name = 'event_subset.pkl'"
      ],
      "metadata": {
        "id": "rOOjV4FMdrfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "READ IN COMBINED FILTERED INDEX DATA W/PERMNO\n",
        "'''\n",
        "\n",
        "filtered_index_data_w_permno = pd.read_pickle((\n",
        "    data_subdir +\n",
        "    file_prefix +\n",
        "    filtered_index_data_w_permno_file_name\n",
        "    ))"
      ],
      "metadata": {
        "id": "LkIq8pCUfGgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **QUERY HELPER FUNCTION**"
      ],
      "metadata": {
        "id": "zVYU5wISeg9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_wrds_query(query_content,\n",
        "                       wrds_session = db,\n",
        "                       output_directory = 'data/',\n",
        "                       output_file = None):\n",
        "\n",
        "    query_result = db.raw_sql(query_content)\n",
        "\n",
        "    if output_file is not None:\n",
        "        output_path = f\"\"\"{output_directory}{output_file}\"\"\"\n",
        "        print(f\"\"\"Writing query result to: {output_path}\"\"\")\n",
        "\n",
        "        if output_file.endswith('.csv'):\n",
        "            query_result.to_csv(output_path)\n",
        "        elif output_file.endswith('.pkl'):\n",
        "            query_result.to_pickle(output_path)\n",
        "        else:\n",
        "            raise Exception(\"Invalid File Format Provided For Output\")\n",
        "        print(f\"\"\"Query result successfully written.\"\"\")\n",
        "    else:\n",
        "        print(f\"\"\"Warning: output is not saved to Google Drive.\"\"\")\n",
        "\n",
        "    return query_result"
      ],
      "metadata": {
        "id": "6u_q8jX8edSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DATA WRANGLING**"
      ],
      "metadata": {
        "id": "bmaEVmUley5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Step 1:**\n",
        "\n",
        "* **Create the event study date calendars for all possible event dates**\n",
        "    * To do so, we utilize CRSP dsf to obtain all distinct dates in the date range being considered; this provides us a calendar of all trading dates in the period (note: not calendar dates)\n",
        "    * Estimation window set to begin 252 trading days prior to each event date (as there are approximately 252 trading days per year)\n",
        "    * Estimation window set to end 60 days prior to each event date (as there are approximately 60 trading days in a quarter, thus providing an approx. 1 quarter gap between estimation window and event)\n",
        "    * Set event window start and end dates for two event window sizes: one 3 day window centered around the event, and one 10 day window centered around the event"
      ],
      "metadata": {
        "id": "8I_9xhSMe2CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_event_dates = f\"\"\"\n",
        "with\n",
        "distinct_dates as\n",
        "(\n",
        "    select distinct\n",
        "        date as event_date\n",
        "    from crsp.dsf\n",
        "    where date between '2004-01-01' and '2020-01-15'\n",
        "),\n",
        "event_study_dates as\n",
        "(\n",
        "    select\n",
        "        event_date,\n",
        "        lag(event_date, 252) over (order by event_date asc)\n",
        "            as est_per_start,\n",
        "        lag(event_date, 60) over (order by event_date asc)\n",
        "            as est_per_end,\n",
        "        lag(event_date, 5) over (order by event_date asc)\n",
        "            as event_wind_start,\n",
        "        lead(event_date, 5) over (order by event_date asc)\n",
        "            as event_wind_end\n",
        "    from distinct_dates\n",
        ")\n",
        "select *\n",
        "from event_study_dates\n",
        "where event_date between '2005-01-01' and '2019-12-31'\n",
        "order by event_date;\"\"\"\n",
        "\n",
        "event_dates = execute_wrds_query(q_event_dates)\n",
        "\n",
        "for col in event_dates.columns:\n",
        "    event_dates[col] = pd.to_datetime(event_dates[col])"
      ],
      "metadata": {
        "id": "XR4ysWTTe5ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Step 2:**\n",
        "\n",
        "* **Create a dataframe merging the event study calendar created above with the relevant data from the file containing Edgar index data matched to PERMNOs**\n",
        "    * Before the merge, drop any columns not needed for the event study component - keep PERMNO, event date, and event period (YYYYMM)\n",
        "    * In Step 3, we'll only retain data related to events that do not have missing return data in CRSP for the corresponding PERMNO during the estimation and event windows\n",
        "    * Additionally, we will merge in this step on event date, which allows only for event dates that occur on trading days"
      ],
      "metadata": {
        "id": "nC4SD7Gce-1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_index_data_w_permno = filtered_index_data_w_permno.filter(\n",
        "    ['event_id','period', 'permno', 'event_date'])\n",
        "\n",
        "index_permno_event_dates = filtered_index_data_w_permno \\\n",
        "    .merge(event_dates, on='event_date')\n",
        "\n",
        "index_permno_event_dates_dict = {x: index_permno_event_dates[\n",
        "    index_permno_event_dates['period']==x\n",
        "    ] for x in index_permno_event_dates.period.unique()}\n",
        "\n",
        "events_no_missing_data_lst = []"
      ],
      "metadata": {
        "id": "jOsltvgAe_fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in index_permno_event_dates_dict.items():\n",
        "    # Convert datetime values to string to facilitate using as json recordset\n",
        "    json_index_permno_event_dates = v.copy()\n",
        "\n",
        "    for col in json_index_permno_event_dates.columns:\n",
        "        if json_index_permno_event_dates[col].dtype == 'datetime64[ns]':\n",
        "            json_index_permno_event_dates[\n",
        "                col] = json_index_permno_event_dates[col].astype(str)\n",
        "\n",
        "    # Convert pandas dataframe to JSON for use in query\n",
        "    json_estimation_window = json_index_permno_event_dates[\n",
        "        ['event_id',\n",
        "         'period',\n",
        "         'permno',\n",
        "         'est_per_start',\n",
        "         'est_per_end',\n",
        "         'event_wind_start',\n",
        "         'event_wind_end']].to_json(orient=\"records\")\n",
        "\n",
        "    q_events_no_missing_data = f\"\"\"\n",
        "with\n",
        "windows_data as\n",
        "(select\n",
        "    x.event_id,x.permno,x.est_per_start,\n",
        "    x.est_per_end,x.event_wind_start,x.event_wind_end\n",
        " from json_to_recordset('{json_estimation_window}') as x(\n",
        "            event_id int,permno float,est_per_start date,\n",
        "            est_per_end date,event_wind_start date,event_wind_end date)),\n",
        "\n",
        "crsp_daily as\n",
        "(select\n",
        "    permno,date as date_ret,ret\n",
        " from crsp_a_stock.dsf\n",
        " where ret is not null and permno in (select distinct permno from windows_data)\n",
        "    and date between (select min(est_per_start) from windows_data)\n",
        "        and (select max(event_wind_end) from windows_data)),\n",
        "\n",
        "estimation_window_data as\n",
        "(select\n",
        "    events.event_id,events.permno,crsp.date_ret,crsp.ret\n",
        " from windows_data events left join crsp_daily crsp\n",
        "    on events.permno = crsp.permno\n",
        "    and crsp.date_ret between events.est_per_start and events.est_per_end),\n",
        "\n",
        "event_period_data as\n",
        "(select\n",
        "    events.event_id,crsp.ret\n",
        " from windows_data events left join crsp_daily crsp\n",
        "    on events.permno = crsp.permno\n",
        "    and crsp.date_ret between events.event_wind_start and events.event_wind_end),\n",
        "\n",
        "estimation_window_counts as\n",
        "(select\n",
        "    event_id, count(ret) as num_returns_est_window\n",
        " from estimation_window_data group by 1),\n",
        "\n",
        "event_window_counts as\n",
        "(select\n",
        "    event_id, count(ret) as num_returns_event_window\n",
        " from event_period_data group by 1)\n",
        "\n",
        "select\n",
        "    coalesce(est.event_id, event.event_id) as event_id,\n",
        "    est.num_returns_est_window, event.num_returns_event_window\n",
        "from estimation_window_counts est join event_window_counts event\n",
        "    on est.event_id = event.event_id\n",
        "where est.num_returns_est_window = 193 and event.num_returns_event_window = 11;\n",
        "\"\"\"\n",
        "\n",
        "    events_no_missing_data_per = execute_wrds_query(q_events_no_missing_data)\n",
        "    events_no_missing_data_lst.append(events_no_missing_data_per)\n",
        "\n",
        "events_no_missing_data = pd.concat(events_no_missing_data_lst\n",
        "                                   ).sort_values(by=['event_id'])\n",
        "\n",
        "event_subset = index_permno_event_dates.merge(events_no_missing_data,\n",
        "                                              on='event_id'\n",
        "                                              ).drop(columns = [\n",
        "                                                  'num_returns_est_window',\n",
        "                                                  'num_returns_event_window'])"
      ],
      "metadata": {
        "id": "ajt9ttJjfpDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_subset.to_pickle((\n",
        "    data_subdir +\n",
        "    file_prefix +\n",
        "    event_subset_file_name\n",
        "    ))"
      ],
      "metadata": {
        "id": "jwWmkSahfp05"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
